{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b0e417d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3432548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_soft_device_placement(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf4bf103",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SAMPLES = 50000\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# def load_conversations(path_to_movie_lines, path_to_movie_conversations):\n",
    "#     id2line = {}\n",
    "#     with open(path_to_movie_lines, errors=\"ignore\") as file:\n",
    "#         lines = file.readlines()\n",
    "#     for line in lines:\n",
    "#         parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "#         id2line[parts[0]] = parts[4]\n",
    "    \n",
    "#     inputs, outputs = [], []\n",
    "#     with open(path_to_movie_conversations, errors=\"ignore\") as file:\n",
    "#         lines = file.readlines()\n",
    "#     for line in lines:\n",
    "#         parts = line.replace('\\n', '').split(' +++$+++ ')\n",
    "#         conversation = [line[1:-1] for line in parts[3][1:-1].split(\", \")]\n",
    "#         for i in range(len(conversation)-1):\n",
    "#             inputs.append(preprocess_sentence(id2line[conversation[i]]))\n",
    "#             outputs.append(preprocess_sentence(id2line[conversation[i+1]]))\n",
    "#             if len(inputs) >= MAX_SAMPLES:\n",
    "#                 return inputs, outputs\n",
    "#     return inputs, outputs\n",
    "def load_conversations(docs_fn):\n",
    "    with open(docs_fn, \"r\") as f:\n",
    "        docs = json.load(f)\n",
    "    \n",
    "    inputs, outputs = [], []\n",
    "    for doc in docs[\"docs\"]:\n",
    "        sents = nltk.tokenize.sent_tokenize(doc)\n",
    "        \n",
    "        for i in range(len(sents)-1):\n",
    "            inputs.append(preprocess_sentence(sents[i]))\n",
    "            outputs.append(preprocess_sentence(sents[i+1]))\n",
    "            if len(inputs) >= MAX_SAMPLES:\n",
    "                return inputs, outputs\n",
    "    \n",
    "    return inputs, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d09b9b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = load_conversations(\"chatbot_docs_no_pdf.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2ab7631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample question: the us does not guarantee housing assistance for families with low incomes , and us affordable housing programs are consistently underfunded , which helps explain the high housing costs faced by us renters pdf .\n",
      "Sample answer: in france , affordable housing funds are consistently available , and housing assistance can be used to help fund housing construction .\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample question: {questions[19]}\")\n",
    "print(f\"Sample answer: {answers[19]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b61484",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    questions + answers, target_vocab_size=2**13\n",
    ")\n",
    "\n",
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size+1]\n",
    "\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c6ed6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized sample question [8, 3885, 1, 12, 7, 341, 15, 1891, 2124, 1, 4, 7, 157, 32, 23, 485, 5, 108, 312, 7, 542, 3]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokenized sample question {tokenizer.encode(questions[20])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf93b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 35\n",
    "\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "        \n",
    "        if len(sentence1) <= MAX_LENGTH and len(sentence2) <= MAX_LENGTH:\n",
    "            tokenized_inputs.append(sentence1)\n",
    "            tokenized_outputs.append(sentence2)\n",
    "    \n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding=\"post\"\n",
    "    )\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding=\"post\"\n",
    "    )\n",
    "    \n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09980f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(questions, answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a228498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 7547\n",
      "Number of samples: 1938\n"
     ]
    }
   ],
   "source": [
    "print(f\"Vocab size: {VOCAB_SIZE}\")\n",
    "print(f\"Number of samples: {len(questions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06beee43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 14:41:22.326404: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-09 14:41:22.326548: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        \"inputs\": questions,\n",
    "        \"dec_inputs\": answers[:, :-1]\n",
    "    },\n",
    "    {\n",
    "        \"outputs\": answers[:, 1:]\n",
    "    }\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a036a7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset element_spec=({'inputs': TensorSpec(shape=(None, 35), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(None, 34), dtype=tf.int32, name=None)}, {'outputs': TensorSpec(shape=(None, 34), dtype=tf.int32, name=None)})>\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e4ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask):\n",
    "    \"\"\"Calculate the attention weights. \"\"\"\n",
    "    matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "    logits = matmul_qk / tf.math.sqrt(depth)\n",
    "\n",
    "    # add the mask to zero out padding tokens\n",
    "    if mask is not None:\n",
    "        logits += (mask * -1e9)\n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k)\n",
    "    attention_weights = tf.nn.softmax(logits, axis=-1)\n",
    "\n",
    "    output = tf.matmul(attention_weights, value)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b9ecd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__(name=name)\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        assert d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = d_model // self.num_heads\n",
    "\n",
    "        self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
    "        self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(units=d_model)\n",
    "\n",
    "    def split_heads(self, inputs, batch_size):\n",
    "        inputs = tf.reshape(\n",
    "            inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
    "            'value'], inputs['mask']\n",
    "        batch_size = tf.shape(query)[0]\n",
    "\n",
    "        # linear layers\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # split heads\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # scaled dot-product attention\n",
    "        scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "\n",
    "        # concatenation of heads\n",
    "        concat_attention = tf.reshape(scaled_attention,\n",
    "                                      (batch_size, -1, self.d_model))\n",
    "\n",
    "        # final linear layer\n",
    "        outputs = self.dense(concat_attention)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d1f135d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(x):\n",
    "    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n",
    "    # (batch_size, 1, 1, sequence length)\n",
    "    return mask[:, tf.newaxis, tf.newaxis, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3badd900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 0. 1. 0. 1.]]]\n",
      "\n",
      "\n",
      " [[[1. 1. 1. 0. 0.]]]], shape=(2, 1, 1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_padding_mask(tf.constant([[1, 2, 0, 3, 0], [0, 0, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32fc1550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(x):\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    padding_mask = create_padding_mask(x)\n",
    "    return tf.maximum(look_ahead_mask, padding_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4eb7470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0. 1. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 1. 1.]\n",
      "   [0. 0. 1. 0. 1.]\n",
      "   [0. 0. 1. 0. 0.]]]], shape=(1, 1, 5, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(create_look_ahead_mask(tf.constant([[1, 2, 0, 4, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97224d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        # apply sin to even index in the array\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        # apply cos to odd index in the array\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "115679d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_pos_encoding = PositionalEncoding(50, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e436ee3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.95375264, -0.14402871,  0.99899036,  0.00437428, -0.99978465,\n",
       "       -0.09193528,  0.9766856 ,  0.3818315 , -0.81590474, -0.7763137 ,\n",
       "        0.35584706,  0.99999905,  0.39289138, -0.65989774, -0.97260624,\n",
       "       -0.28576124,  0.6590901 ,  0.99249995,  0.48723227, -0.3868527 ,\n",
       "       -0.95549494, -0.85577035, -0.21199208,  0.5405312 ,  0.970674  ,\n",
       "        0.8835413 ,  0.36996835, -0.29602593, -0.81690377, -0.99984586,\n",
       "       -0.8094759 , -0.3474314 ,  0.2111988 ,  0.6891934 ,  0.96044624,\n",
       "        0.9742649 ,  0.7525239 ,  0.36879084, -0.07963098, -0.49772498,\n",
       "       -0.8114557 , -0.97728807, -0.983379  , -0.84475356, -0.5951851 ,\n",
       "       -0.27819258,  0.06106959,  0.38204202,  0.65274966,  0.8516537 ,\n",
       "        0.96775836,  0.9994905 ,  0.9528382 ,  0.839197  ,  0.6732368 ,\n",
       "        0.47101328,  0.24844028,  0.02015853, -0.20120731, -0.405448  ,\n",
       "       -0.5848968 , -0.7343527 , -0.8508527 , -0.93336755, -0.9824525 ,\n",
       "       -0.9998956 , -0.9883813 , -0.9511915 , -0.8919466 , -0.81439406,\n",
       "       -0.7222393 , -0.6190218 , -0.50802386, -0.3922157 , -0.27421883,\n",
       "       -0.15629874, -0.04036673,  0.07200552,  0.17956083,  0.28132904,\n",
       "        0.3765969 ,  0.46487546,  0.54586977,  0.61944884,  0.6856175 ,\n",
       "        0.7444923 ,  0.7962778 ,  0.8412466 ,  0.879723  ,  0.912068  ,\n",
       "        0.9386654 ,  0.9599125 ,  0.9762113 ,  0.9879614 ,  0.9955546 ,\n",
       "        0.9993705 ,  0.99977356,  0.99711055,  0.99170905,  0.9838767 ,\n",
       "        0.97390056,  0.9620472 ,  0.948563  ,  0.9336744 ,  0.91758925,\n",
       "        0.900497  ,  0.88256973,  0.8639636 ,  0.84481937,  0.82526374,\n",
       "        0.80541015,  0.78536   ,  0.7652033 ,  0.7450199 ,  0.7248802 ,\n",
       "        0.7048459 ,  0.68497103,  0.6653025 ,  0.64588064,  0.6267399 ,\n",
       "        0.60791   ,  0.58941513,  0.57127595,  0.5535091 ,  0.53612787,\n",
       "        0.51914245,  0.5025605 ,  0.48638725,  0.4706259 ,  0.45527783,\n",
       "        0.4403427 ,  0.4258189 ,  0.4117035 ,  0.3979926 ,  0.38468143,\n",
       "        0.37176436,  0.35923514,  0.34708703,  0.33531263,  0.3239045 ,\n",
       "        0.31285462,  0.30215496,  0.2917972 ,  0.2817729 ,  0.2720736 ,\n",
       "        0.26269078,  0.25361595,  0.24484053,  0.23635623,  0.22815457,\n",
       "        0.2202274 ,  0.21256655,  0.20516407,  0.19801196,  0.19110264,\n",
       "        0.18442838,  0.17798205,  0.17175615,  0.16574384,  0.15993805,\n",
       "        0.15433231,  0.14891993,  0.14369449,  0.13865   ,  0.13378027,\n",
       "        0.12907965,  0.12454231,  0.12016293,  0.11593602,  0.11185654,\n",
       "        0.10791937,  0.10411981,  0.100453  ,  0.09691455,  0.09349991,\n",
       "        0.09020496,  0.08702551,  0.08395752,  0.08099725,  0.07814085,\n",
       "        0.07538485,  0.07272564,  0.07015996,  0.06768445,  0.06529608,\n",
       "        0.06299172,  0.0607685 ,  0.05862353,  0.05655414,  0.05455761,\n",
       "        0.05263146,  0.05077317,  0.0489804 ,  0.04725084,  0.04558224,\n",
       "        0.04397251,  0.04241953,  0.04092135,  0.03947601,  0.03808169,\n",
       "        0.03673655,  0.0354389 ,  0.03418703,  0.03297938,  0.03181433,\n",
       "        0.03069043,  0.02960619,  0.02856026,  0.02755123,  0.02657786,\n",
       "        0.02563886,  0.024733  ,  0.02385915,  0.02301615,  0.02220294,\n",
       "        0.02141844,  0.02066167,  0.01993161,  0.01922735,  0.01854796,\n",
       "        0.01789258,  0.01726034,  0.01665046,  0.0160621 ,  0.01549454,\n",
       "        0.01494704,  0.01441887,  0.01390936,  0.01341785,  0.01294372,\n",
       "        0.01248633,  0.01204511,  0.01161947,  0.01120888,  0.01081279,\n",
       "        0.0104307 ,  0.0100621 ,  0.00970654,  0.00936353,  0.00903265,\n",
       "        0.00871346,  0.00840555,  0.00810852,  0.00782198,  0.00754557,\n",
       "        0.00727893,  0.00702171,  0.00677357,  0.00653421,  0.0063033 ,\n",
       "        0.00608056,  0.00586568,  0.0056584 ,  0.00545844,  0.00526556,\n",
       "        0.00507948,  0.30059254, -0.98957354, -0.0449253 ,  0.9999904 ,\n",
       "        0.02075248, -0.995765  , -0.21467486,  0.92423195,  0.5781864 ,\n",
       "       -0.6303467 , -0.9345442 ,  0.0013713 ,  0.9195849 ,  0.7513554 ,\n",
       "       -0.23245889, -0.9583008 , -0.752064  ,  0.122245  ,  0.8732724 ,\n",
       "        0.92214155,  0.29500747, -0.5173559 , -0.9772714 , -0.841324  ,\n",
       "       -0.24039966,  0.46835327,  0.92904437,  0.95517987,  0.576774  ,\n",
       "       -0.01755683, -0.5871531 , -0.9377054 , -0.9774431 , -0.72457737,\n",
       "       -0.27846554,  0.225406  ,  0.6585649 ,  0.9295124 ,  0.9968244 ,\n",
       "        0.8673349 ,  0.5844139 ,  0.21191502, -0.18156475, -0.53515553,\n",
       "       -0.8035886 , -0.96052533, -0.99813354, -0.9241449 , -0.75757366,\n",
       "       -0.5241049 , -0.25188038,  0.03191801,  0.30347893,  0.54382753,\n",
       "        0.739427  ,  0.8821261 ,  0.96864724,  0.9997968 ,  0.9795487 ,\n",
       "        0.9141181 ,  0.8111077 ,  0.67876804,  0.52540433,  0.35892195,\n",
       "        0.18651293,  0.01445244, -0.15199456, -0.30860123, -0.4521407 ,\n",
       "       -0.5803122 , -0.69164324, -0.78537387, -0.861343  , -0.9198733 ,\n",
       "       -0.9616673 , -0.9877098 , -0.9991849 , -0.9974042 , -0.9837469 ,\n",
       "       -0.95961136, -0.92637724, -0.8853761 , -0.83787   , -0.78503704,\n",
       "       -0.72796196, -0.6676311 , -0.6049311 , -0.5406516 , -0.47548646,\n",
       "       -0.4100389 , -0.34482938, -0.2802999 , -0.21682134, -0.15470059,\n",
       "       -0.09418613, -0.03547584,  0.02127852,  0.07596423,  0.12850364,\n",
       "        0.17884816,  0.22697523,  0.27288312,  0.31658855,  0.35812312,\n",
       "        0.3975299 ,  0.43486217,  0.47018152,  0.5035542 ,  0.5350516 ,\n",
       "        0.5647475 ,  0.5927178 ,  0.61903936,  0.64378875,  0.66704226,\n",
       "        0.6888749 ,  0.7093604 ,  0.7285703 ,  0.74657387,  0.7634384 ,\n",
       "        0.7792285 ,  0.79400593,  0.8078303 ,  0.82075804,  0.8328431 ,\n",
       "        0.8441368 ,  0.85468775,  0.864542  ,  0.87374336,  0.88233286,\n",
       "        0.89034945,  0.8978298 ,  0.9048084 ,  0.9113178 ,  0.9173886 ,\n",
       "        0.9230494 ,  0.92832714,  0.9332471 ,  0.93783295,  0.9421069 ,\n",
       "        0.9460898 ,  0.949801  ,  0.9532588 ,  0.9564802 ,  0.9594811 ,\n",
       "        0.96227646,  0.96488005,  0.967305  ,  0.96956336,  0.97166646,\n",
       "        0.97362494,  0.97544855,  0.97714657,  0.9787276 ,  0.9801996 ,\n",
       "        0.98157007,  0.98284596,  0.98403376,  0.9851395 ,  0.98616886,\n",
       "        0.98712707,  0.988019  ,  0.9888493 ,  0.9896221 ,  0.9903414 ,\n",
       "        0.991011  ,  0.99163425,  0.9922143 ,  0.99275416,  0.9932567 ,\n",
       "        0.99372435,  0.99415964,  0.9945648 ,  0.99494183,  0.9952927 ,\n",
       "        0.9956193 ,  0.9959232 ,  0.9962061 ,  0.9964693 ,  0.99671435,\n",
       "        0.99694234,  0.99715453,  0.997352  ,  0.99753577,  0.9977068 ,\n",
       "        0.9978659 ,  0.99801403,  0.9981519 ,  0.99828017,  0.99839956,\n",
       "        0.9985106 ,  0.998614  ,  0.9987102 ,  0.99879974,  0.99888307,\n",
       "        0.9989606 ,  0.99903274,  0.9990999 ,  0.9991624 ,  0.9992205 ,\n",
       "        0.9992746 ,  0.999325  ,  0.9993718 ,  0.99941546,  0.99945605,\n",
       "        0.9994938 ,  0.99952894,  0.99956167,  0.99959207,  0.9996204 ,\n",
       "        0.9996467 ,  0.9996713 ,  0.9996941 ,  0.9997153 ,  0.9997351 ,\n",
       "        0.9997535 ,  0.9997706 ,  0.9997865 ,  0.99980134,  0.99981517,\n",
       "        0.999828  ,  0.9998399 ,  0.99985105,  0.99986136,  0.999871  ,\n",
       "        0.99987996,  0.9998883 ,  0.99989605,  0.99990326,  0.99991   ,\n",
       "        0.99991626,  0.99992204,  0.99992746,  0.99993247,  0.9999372 ,\n",
       "        0.9999415 ,  0.9999456 ,  0.9999494 ,  0.9999529 ,  0.9999562 ,\n",
       "        0.99995923,  0.99996203,  0.99996465,  0.9999671 ,  0.9999694 ,\n",
       "        0.9999715 ,  0.99997354,  0.9999753 ,  0.99997705,  0.99997866,\n",
       "        0.99998015,  0.9999815 ,  0.9999828 ,  0.99998397,  0.9999851 ,\n",
       "        0.9999861 ,  0.9999871 ], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_pos_encoding.pos_encoding.numpy()[0][49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8b7a12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    attention = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention\")({\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "    attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
    "    attention = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(inputs + attention)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention + outputs)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe56f368",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_encoder_layer = encoder_layer(\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_encoder_layer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe7bb493",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name=\"encoder\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = encoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name=\"encoder_layer_{}\".format(i),\n",
    "        )([outputs, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, padding_mask], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb3be108",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_encoder = encoder(\n",
    "    vocab_size=8192,\n",
    "    num_layers=2,\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "685cdfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_layer(units, d_model, num_heads, dropout, name=\"decoder_layer\"):\n",
    "    inputs = tf.keras.Input(shape=(None, d_model), name=\"inputs\")\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name=\"encoder_outputs\")\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name=\"look_ahead_mask\")\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    attention1 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_1\")(inputs={\n",
    "          'query': inputs,\n",
    "          'key': inputs,\n",
    "          'value': inputs,\n",
    "          'mask': look_ahead_mask\n",
    "      })\n",
    "    attention1 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention1 + inputs)\n",
    "\n",
    "    attention2 = MultiHeadAttention(\n",
    "      d_model, num_heads, name=\"attention_2\")(inputs={\n",
    "          'query': attention1,\n",
    "          'key': enc_outputs,\n",
    "          'value': enc_outputs,\n",
    "          'mask': padding_mask\n",
    "      })\n",
    "    attention2 = tf.keras.layers.Dropout(rate=dropout)(attention2)\n",
    "    attention2 = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(attention2 + attention1)\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention2)\n",
    "    outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
    "    outputs = tf.keras.layers.LayerNormalization(\n",
    "      epsilon=1e-6)(outputs + attention2)\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e01df873",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_decoder_layer = decoder_layer(\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_decoder_layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b8b035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(vocab_size,\n",
    "            num_layers,\n",
    "            units,\n",
    "            d_model,\n",
    "            num_heads,\n",
    "            dropout,\n",
    "            name='decoder'):\n",
    "    inputs = tf.keras.Input(shape=(None,), name='inputs')\n",
    "    enc_outputs = tf.keras.Input(shape=(None, d_model), name='encoder_outputs')\n",
    "    look_ahead_mask = tf.keras.Input(\n",
    "      shape=(1, None, None), name='look_ahead_mask')\n",
    "    padding_mask = tf.keras.Input(shape=(1, 1, None), name='padding_mask')\n",
    "\n",
    "    embeddings = tf.keras.layers.Embedding(vocab_size, d_model)(inputs)\n",
    "    embeddings *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
    "    embeddings = PositionalEncoding(vocab_size, d_model)(embeddings)\n",
    "\n",
    "    outputs = tf.keras.layers.Dropout(rate=dropout)(embeddings)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        outputs = decoder_layer(\n",
    "            units=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout,\n",
    "            name='decoder_layer_{}'.format(i),\n",
    "        )(inputs=[outputs, enc_outputs, look_ahead_mask, padding_mask])\n",
    "\n",
    "    return tf.keras.Model(\n",
    "      inputs=[inputs, enc_outputs, look_ahead_mask, padding_mask],\n",
    "      outputs=outputs,\n",
    "      name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e86a0000",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_decoder = decoder(\n",
    "    vocab_size=8192,\n",
    "    num_layers=2,\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_decoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3a2d453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer(vocab_size,\n",
    "                num_layers,\n",
    "                units,\n",
    "                d_model,\n",
    "                num_heads,\n",
    "                dropout,\n",
    "                name=\"transformer\"):\n",
    "    inputs = tf.keras.Input(shape=(None,), name=\"inputs\")\n",
    "    dec_inputs = tf.keras.Input(shape=(None,), name=\"dec_inputs\")\n",
    "\n",
    "    enc_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='enc_padding_mask')(inputs)\n",
    "    # mask the future tokens for decoder inputs at the 1st attention block\n",
    "    look_ahead_mask = tf.keras.layers.Lambda(\n",
    "      create_look_ahead_mask,\n",
    "      output_shape=(1, None, None),\n",
    "      name='look_ahead_mask')(dec_inputs)\n",
    "    # mask the encoder outputs for the 2nd attention block\n",
    "    dec_padding_mask = tf.keras.layers.Lambda(\n",
    "      create_padding_mask, output_shape=(1, 1, None),\n",
    "      name='dec_padding_mask')(inputs)\n",
    "\n",
    "    enc_outputs = encoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[inputs, enc_padding_mask])\n",
    "\n",
    "    dec_outputs = decoder(\n",
    "      vocab_size=vocab_size,\n",
    "      num_layers=num_layers,\n",
    "      units=units,\n",
    "      d_model=d_model,\n",
    "      num_heads=num_heads,\n",
    "      dropout=dropout,\n",
    "    )(inputs=[dec_inputs, enc_outputs, look_ahead_mask, dec_padding_mask])\n",
    "\n",
    "    outputs = tf.keras.layers.Dense(units=vocab_size, name=\"outputs\")(dec_outputs)\n",
    "\n",
    "    return tf.keras.Model(inputs=[inputs, dec_inputs], outputs=outputs, name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76c2594e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_transformer = transformer(\n",
    "    vocab_size=8192,\n",
    "    num_layers=4,\n",
    "    units=512,\n",
    "    d_model=128,\n",
    "    num_heads=4,\n",
    "    dropout=0.3,\n",
    "    name=\"sample_transformer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36d923b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyper-parameters\n",
    "NUM_LAYERS = 6\n",
    "D_MODEL = 512\n",
    "NUM_HEADS = 8\n",
    "UNITS = 2048\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65f69539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "      from_logits=True, reduction='none')(y_true, y_pred)\n",
    "\n",
    "    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n",
    "    loss = tf.multiply(loss, mask)\n",
    "\n",
    "    return tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "12bdef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        arg1 = tf.math.rsqrt(step)\n",
    "        arg2 = step * (self.warmup_steps**-1.5)\n",
    "\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7c5e56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    # ensure labels have shape (batch_size, MAX_LENGTH - 1)\n",
    "    y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dd3674ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " dec_inputs (InputLayer)        [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " enc_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " encoder (Functional)           (None, None, 512)    22778368    ['inputs[0][0]',                 \n",
      "                                                                  'enc_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " look_ahead_mask (Lambda)       (None, 1, None, Non  0           ['dec_inputs[0][0]']             \n",
      "                                e)                                                                \n",
      "                                                                                                  \n",
      " dec_padding_mask (Lambda)      (None, 1, 1, None)   0           ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " decoder (Functional)           (None, None, 512)    29088256    ['dec_inputs[0][0]',             \n",
      "                                                                  'encoder[0][0]',                \n",
      "                                                                  'look_ahead_mask[0][0]',        \n",
      "                                                                  'dec_padding_mask[0][0]']       \n",
      "                                                                                                  \n",
      " outputs (Dense)                (None, None, 7547)   3871611     ['decoder[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 55,738,235\n",
      "Trainable params: 55,738,235\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea70b8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-09 14:41:33.891871: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-03-09 14:41:33.893139: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 25s 401ms/step - loss: 5.6620 - accuracy: 7.5882e-05\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 11s 340ms/step - loss: 5.4120 - accuracy: 0.0259\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 10s 329ms/step - loss: 5.1613 - accuracy: 0.0285\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 10s 323ms/step - loss: 4.9798 - accuracy: 0.0290\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 4.7729 - accuracy: 0.0583\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 4.5183 - accuracy: 0.0673\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 10s 330ms/step - loss: 4.3215 - accuracy: 0.0725\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 4.1689 - accuracy: 0.0742\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 4.0448 - accuracy: 0.0816\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 3.9530 - accuracy: 0.0922\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 10s 331ms/step - loss: 3.8739 - accuracy: 0.1033\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 10s 336ms/step - loss: 3.8009 - accuracy: 0.1110\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 11s 337ms/step - loss: 3.7207 - accuracy: 0.1192\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 3.6340 - accuracy: 0.1284\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 3.5563 - accuracy: 0.1349\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 10s 331ms/step - loss: 3.4660 - accuracy: 0.1437\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 10s 328ms/step - loss: 3.3800 - accuracy: 0.1526\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 3.3019 - accuracy: 0.1593\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 11s 337ms/step - loss: 3.2111 - accuracy: 0.1676\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 10s 333ms/step - loss: 3.1379 - accuracy: 0.1717\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 10s 330ms/step - loss: 3.0507 - accuracy: 0.1803\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 2.9745 - accuracy: 0.1867\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 10s 331ms/step - loss: 2.8997 - accuracy: 0.1928\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 10s 324ms/step - loss: 2.8190 - accuracy: 0.1987\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 10s 327ms/step - loss: 2.7502 - accuracy: 0.2040\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 10s 331ms/step - loss: 2.6708 - accuracy: 0.2122\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 2.6011 - accuracy: 0.2171\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 2.5196 - accuracy: 0.2239\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 10s 328ms/step - loss: 2.4357 - accuracy: 0.2333\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 2.3608 - accuracy: 0.2402\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 2.2850 - accuracy: 0.2472\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 10s 320ms/step - loss: 2.2235 - accuracy: 0.2542\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 10s 319ms/step - loss: 2.1315 - accuracy: 0.2640\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 10s 321ms/step - loss: 2.0488 - accuracy: 0.2743\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 10s 325ms/step - loss: 1.9504 - accuracy: 0.2887\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 10s 321ms/step - loss: 1.8742 - accuracy: 0.2976\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 1.8117 - accuracy: 0.3061\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 10s 333ms/step - loss: 1.7113 - accuracy: 0.3190\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 10s 327ms/step - loss: 1.6358 - accuracy: 0.3294\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 10s 334ms/step - loss: 1.5557 - accuracy: 0.3431\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 10s 333ms/step - loss: 1.4499 - accuracy: 0.3594\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 10s 330ms/step - loss: 1.3842 - accuracy: 0.3697\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 10s 318ms/step - loss: 1.2905 - accuracy: 0.3868\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 10s 322ms/step - loss: 1.2242 - accuracy: 0.3966\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 10s 317ms/step - loss: 1.1193 - accuracy: 0.4170\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 10s 321ms/step - loss: 1.0520 - accuracy: 0.4287\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 10s 332ms/step - loss: 0.9578 - accuracy: 0.4491\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 10s 332ms/step - loss: 0.8595 - accuracy: 0.4701\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 11s 338ms/step - loss: 0.7912 - accuracy: 0.4838\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 10s 326ms/step - loss: 0.7233 - accuracy: 0.4976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2994436a0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b3b379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow_metal)",
   "language": "python",
   "name": "tensorflow_metal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
